{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7154116,"sourceType":"datasetVersion","datasetId":4131177},{"sourceId":7156755,"sourceType":"datasetVersion","datasetId":4133163},{"sourceId":7157593,"sourceType":"datasetVersion","datasetId":4133735},{"sourceId":7157605,"sourceType":"datasetVersion","datasetId":4133744}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.utils.data as Data, Dataset, DataLoader\nimport torchvision\nfrom torchvision import transforms\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\nimport os\nimport copy\nimport glob\nimport time\nimport pandas as pd\nfrom typing import Dict, List, Tuple\nfrom PIL import Image\nimport random","metadata":{"id":"F1qddAHQ3hTv","execution":{"iopub.status.busy":"2023-12-10T01:39:39.102170Z","iopub.execute_input":"2023-12-10T01:39:39.102458Z","iopub.status.idle":"2023-12-10T01:39:41.265652Z","shell.execute_reply.started":"2023-12-10T01:39:39.102428Z","shell.execute_reply":"2023-12-10T01:39:41.264838Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"DOANLOAD_DATASET = True\nLR = 0.0001\nBATCH_SIZE=32\nEPOCH = 30\nOUTPUT_PATH = '/kaggle/working/'","metadata":{"id":"wHR8AhBT3tel","execution":{"iopub.status.busy":"2023-12-10T01:39:41.267026Z","iopub.execute_input":"2023-12-10T01:39:41.267435Z","iopub.status.idle":"2023-12-10T01:39:41.271459Z","shell.execute_reply.started":"2023-12-10T01:39:41.267408Z","shell.execute_reply":"2023-12-10T01:39:41.270665Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# 檢查GPU是否可用\nif torch.cuda.is_available():\n    device = torch.device('cuda')\n    print(torch.cuda.get_device_name(0))\nelse:\n    device = torch.device('cpu')\n    print('GPU not available, using CPU.')","metadata":{"id":"rDNnzpHeWpC6","outputId":"f69a574c-6ad9-4ede-9021-cd275f40d60a","execution":{"iopub.status.busy":"2023-12-10T01:39:41.272494Z","iopub.execute_input":"2023-12-10T01:39:41.272743Z","iopub.status.idle":"2023-12-10T01:39:41.364136Z","shell.execute_reply.started":"2023-12-10T01:39:41.272721Z","shell.execute_reply":"2023-12-10T01:39:41.363266Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Tesla T4\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install dill\nimport dill","metadata":{"id":"8s621vKWTbhE","outputId":"a5ce1d08-895b-480b-c324-b35271d9a478","execution":{"iopub.status.busy":"2023-12-10T01:39:41.366069Z","iopub.execute_input":"2023-12-10T01:39:41.366339Z","iopub.status.idle":"2023-12-10T01:39:54.174956Z","shell.execute_reply.started":"2023-12-10T01:39:41.366314Z","shell.execute_reply":"2023-12-10T01:39:54.173924Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (0.3.7)\n","output_type":"stream"}]},{"cell_type":"code","source":"class CFG:\n    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n    NUM_DEVICES = torch.cuda.device_count()\n    NUM_WORKERS = os.cpu_count()\n    NUM_CLASSES = 45\n    EPOCHS = 7\n    BATCH_SIZE = (\n        32 if torch.cuda.device_count() <= 2\n        else (32 * torch.cuda.device_count())\n    )\n    LR = 0.001\n    APPLY_SHUFFLE = True\n    SEED = 768\n    HEIGHT = 256\n    WIDTH = 256\n    CHANNELS = 3\n    IMAGE_SIZE = (256, 256, 3)","metadata":{"id":"9T7IeL8IMyUo","execution":{"iopub.status.busy":"2023-12-10T01:39:54.176403Z","iopub.execute_input":"2023-12-10T01:39:54.176689Z","iopub.status.idle":"2023-12-10T01:39:54.183734Z","shell.execute_reply.started":"2023-12-10T01:39:54.176662Z","shell.execute_reply":"2023-12-10T01:39:54.182766Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Reload the dataset\nimport torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\n\nDATASET_PATH = '/kaggle/working'\n\n# 加載數據集\nwith open('/kaggle/input/usedata/train_loader.pkl','rb') as f:\n    train_loader = dill.load(f)\nwith open('/kaggle/input/usedata/val_loader.pkl','rb') as f:\n    val_loader = dill.load(f)\nwith open('/kaggle/input/usedata/test_loader.pkl','rb') as f:\n    test_loader = dill.load(f)","metadata":{"id":"7anlEKRMJzgb","execution":{"iopub.status.busy":"2023-12-10T01:39:54.194117Z","iopub.execute_input":"2023-12-10T01:39:54.194441Z","iopub.status.idle":"2023-12-10T01:39:54.244588Z","shell.execute_reply.started":"2023-12-10T01:39:54.194416Z","shell.execute_reply":"2023-12-10T01:39:54.243789Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# 建立存放結果的資料集\nimport os\n\npath = '/kaggle/working/test'\nif not os.path.isdir(path):\n    os.mkdir(path)\n    \npath = '/kaggle/working/train'\nif not os.path.isdir(path):\n    os.mkdir(path)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:39:54.245585Z","iopub.execute_input":"2023-12-10T01:39:54.245856Z","iopub.status.idle":"2023-12-10T01:39:54.251296Z","shell.execute_reply.started":"2023-12-10T01:39:54.245825Z","shell.execute_reply":"2023-12-10T01:39:54.250319Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"class AlexNet(nn.Module):\n\n    def __init__(self, num_classes=45):\n        super(AlexNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=5),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        self.classifier = nn.Linear(256*8*8, num_classes)\n        #self.classifier = nn.Linear(256 * (image_size_after_pooling // 4) * (image_size_after_pooling // 4), num_classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n\ndef alexnet(**kwargs):\n    model = AlexNet(**kwargs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:39:54.252581Z","iopub.execute_input":"2023-12-10T01:39:54.253327Z","iopub.status.idle":"2023-12-10T01:39:54.264081Z","shell.execute_reply.started":"2023-12-10T01:39:54.253291Z","shell.execute_reply":"2023-12-10T01:39:54.263211Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Alexnet","metadata":{}},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\nalexNet = alexnet().cuda()\nalexNet = nn.DataParallel(alexNet)\n\noptimizer = torch.optim.Adam(alexNet.parameters(), lr=LR)\nloss_function = nn.CrossEntropyLoss()\nlocal_train_data = copy.deepcopy(train_loader)\n#local_train_data = DataLoader(train_dataloader, batch_size=batch_size, shuffle=True)\n\n# 容器來儲存每一輪的輸出\ntrain_predict = torch.Tensor().to(device)\ntrain_label = torch.Tensor().to(device)\ntest_predict = torch.Tensor().to(device)\ntest_label = torch.Tensor().to(device)\n\nfor epoch in range(EPOCH):\n    alexNet.train()\n    for step, (x, y) in enumerate(local_train_data):\n        #b_x = Variable(x, requires_grad=False)\n        #b_y = Variable(y, requires_grad=False)\n        b_x = x.to(device)  # 將輸入數據移動到GPU上\n        b_y = y.to(device)  # 將標籤移動到GPU上\n        out = alexNet(b_x)\n        loss = loss_function(out, b_y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if step % 100 == 0:\n            print('Epoch: {} | Step: {} | Loss: {}'.format(epoch + 1, step, loss))\n\n            \nlocal_train_loader = copy.deepcopy(train_loader)\nlocal_test_loader = copy.deepcopy(test_loader)\n\n# 在評估模式下，模型只需要在主 GPU 上執行\nalexNet = alexNet.module\n\n# 測試集\nalexNet.eval()  # 切換到評估模式\nmodel_path = '/kaggle/working/'\ntorch.save(alexNet.state_dict(), model_path+'alexNet.pth')\n\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_train_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = alexNet(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        train_predict = torch.cat((train_predict, out), dim=0)\n        train_label = torch.cat((train_label, b_y), dim=0)\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_test_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = alexNet(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        test_predict = torch.cat((test_predict, out), dim=0)\n        test_label = torch.cat((test_label, b_y), dim=0)\n\n# train_predict、train_label 分別包含了每一輪的模型訓練集預測和標籤\n# test_predict、test_label 分別包含了模型對測試集的預測和標籤\nprint(\"Shape of train_predict:\", train_predict.shape)\nprint(\"Shape of train_label:\", train_label.shape)\nprint(\"Shape of test_predict:\", test_predict.shape)\nprint(\"Shape of test_label:\", test_label.shape)\n\n\noutput_path = OUTPUT_PATH+'train'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':train_predict,'labelVectors':train_label}\ntorch.save(temp_dict, os.path.join(output_path, 'alexNet_train_prediction.pt'))\n\n\noutput_path = OUTPUT_PATH+'test'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':test_predict,'labelVectors':test_label}\ntorch.save(temp_dict, os.path.join(output_path, 'alexNet_test_prediction.pt'))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:39:54.267096Z","iopub.execute_input":"2023-12-10T01:39:54.267418Z","iopub.status.idle":"2023-12-10T01:39:54.278477Z","shell.execute_reply.started":"2023-12-10T01:39:54.267390Z","shell.execute_reply":"2023-12-10T01:39:54.277599Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"\"\\nalexNet = alexnet().cuda()\\nalexNet = nn.DataParallel(alexNet)\\n\\noptimizer = torch.optim.Adam(alexNet.parameters(), lr=LR)\\nloss_function = nn.CrossEntropyLoss()\\nlocal_train_data = copy.deepcopy(train_loader)\\n#local_train_data = DataLoader(train_dataloader, batch_size=batch_size, shuffle=True)\\nfor epoch in range(EPOCH):\\n    alexNet.train()\\n    for step, (x, y) in enumerate(local_train_data):\\n        #b_x = Variable(x, requires_grad=False)\\n        #b_y = Variable(y, requires_grad=False)\\n        b_x = x.to(device)  # 將輸入數據移動到GPU上\\n        b_y = y.to(device)  # 將標籤移動到GPU上\\n        out = alexNet(b_x)\\n        loss = loss_function(out, b_y)\\n\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n\\n        if step % 100 == 0:\\n            print('Epoch: {} | Step: {} | Loss: {}'.format(epoch + 1, step, loss))\\n            \\ntemp_train_loader = copy.deepcopy(train_loader)\\ntemp_train_x, temp_train_y = next(iter(temp_train_loader))\\n\\nalexNet.eval()  # 將模型設置為評估模式\\nwith torch.no_grad():  # 關閉梯度計算\\n    temp_train_x, temp_train_y = temp_train_x.to(device), temp_train_y.to(device)  # 將測試數據移動到GPU上\\n    train_prediction = torch.argmax(alexNet(temp_train_x), 1)\\n    acc = torch.eq(train_prediction, temp_train_y)\\n    accuracy = torch.sum(acc) / acc.shape[0]\\n    print('Accuracy: {:.2%}'.format(accuracy.item()))\\n\\n# 保存模型的方式建議使用 torch.save(model.state_dict(), path) 以保存模型的狀態字典\\noutput_path = OUTPUT_PATH+'train'\\nif not os.path.exists(output_path):\\n    os.mkdir(output_path)\\ntemp_dict = {'predictionVectors':train_prediction.tolist(),'labelVectors':temp_train_y.tolist()}\\ntorch.save(temp_dict, os.path.join(output_path, 'alexNet_train_prediction.pt'))\\n\\nlocal_test_loader = copy.deepcopy(test_loader)\\ntemp_test_x, temp_test_y = next(iter(local_test_loader))\\n\\n#alexNet.eval()  # 將模型設置為評估模式\\nwith torch.no_grad():  # 關閉梯度計算\\n    temp_test_x, temp_test_y = temp_test_x.to(device), temp_test_y.to(device)  # 將測試數據移動到GPU上\\n    prediction = torch.argmax(alexNet(temp_test_x), 1)\\n    acc = torch.eq(prediction, temp_test_y)\\n    accuracy = torch.sum(acc) / acc.shape[0]\\n    print('Accuracy: {:.2%}'.format(accuracy.item()))\\n\\n# 保存模型的方式建議使用 torch.save(model.state_dict(), path) 以保存模型的狀態字典\\noutput_path = OUTPUT_PATH+'test'\\nif not os.path.exists(output_path):\\n    os.mkdir(output_path)\\ntemp_dict = {'predictionVectors':prediction.tolist(),'labelVectors':temp_test_y.tolist()}\\ntorch.save(temp_dict, os.path.join(output_path, 'alexNet_test_prediction.pt'))\\n\""},"metadata":{}}]},{"cell_type":"markdown","source":"# DenseNet","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\nfrom torch.autograd import Variable\n\nclass Bottleneck(nn.Module):\n    def __init__(self, inplanes, expansion=4, growthRate=12, dropRate=0):\n        super(Bottleneck, self).__init__()\n        planes = expansion * growthRate\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, growthRate, kernel_size=3,\n                               padding=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.dropRate = dropRate\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        if self.dropRate > 0:\n            out = F.dropout(out, p=self.dropRate, training=self.training)\n\n        out = torch.cat((x, out), 1)\n\n        return out\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, inplanes, expansion=1, growthRate=12, dropRate=0):\n        super(BasicBlock, self).__init__()\n        planes = expansion * growthRate\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, growthRate, kernel_size=3,\n                               padding=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.dropRate = dropRate\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n        if self.dropRate > 0:\n            out = F.dropout(out, p=self.dropRate, training=self.training)\n\n        out = torch.cat((x, out), 1)\n\n        return out\n\n\nclass Transition(nn.Module):\n    def __init__(self, inplanes, outplanes):\n        super(Transition, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, outplanes, kernel_size=1,\n                               bias=False)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n        out = F.avg_pool2d(out, 2)\n        return out\n\n\nclass DenseNet(nn.Module):\n\n    def __init__(self, depth=40, block=Bottleneck,\n        dropRate=0, num_classes=45, growthRate=12, compressionRate=2):\n        super(DenseNet, self).__init__()\n\n        assert (depth - 4) % 3 == 0, 'depth should be 3n+4'\n        n = (depth - 4) / 3 if block == BasicBlock else (depth - 4) // 6\n\n        self.growthRate = growthRate\n        self.dropRate = dropRate\n\n        # self.inplanes is a global variable used across multiple\n        # helper functions\n        self.inplanes = growthRate * 2\n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, padding=1,\n                               bias=False)\n        self.dense1 = self._make_denseblock(block, n)\n        self.trans1 = self._make_transition(compressionRate)\n        self.dense2 = self._make_denseblock(block, n)\n        self.trans2 = self._make_transition(compressionRate)\n        self.dense3 = self._make_denseblock(block, n)\n        self.bn = nn.BatchNorm2d(self.inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(self.inplanes* 64, num_classes)\n\n        # Weight initialization\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_denseblock(self, block, blocks):\n        layers = []\n        for i in range(blocks):\n            # Currently we fix the expansion ratio as the default value\n            layers.append(block(self.inplanes, growthRate=self.growthRate, dropRate=self.dropRate))\n            self.inplanes += self.growthRate\n\n        return nn.Sequential(*layers)\n\n    def _make_transition(self, compressionRate):\n        inplanes = self.inplanes\n        outplanes = int(math.floor(self.inplanes // compressionRate))\n        self.inplanes = outplanes\n        return Transition(inplanes, outplanes)\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n\n        x = self.trans1(self.dense1(x))\n        x = self.trans2(self.dense2(x))\n        x = self.dense3(x)\n        x = self.bn(x)\n        x = self.relu(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef densenet(**kwargs):\n    '''\n    Constructs a ResNet model.\n    '''\n    return DenseNet(**kwargs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n\nDensenet = densenet().cuda()\n\nDensenet = nn.DataParallel(Densenet)\n\noptimizer = torch.optim.Adam(Densenet.parameters(), lr=LR)\nloss_function = nn.CrossEntropyLoss()\nlocal_train_data = copy.deepcopy(train_loader)\n\nfor epoch in range(EPOCH):\n    Densenet.train()\n    for step, (x, y) in enumerate(local_train_data):\n        # b_x = Variable(x, requires_grad=False)\n        # b_y = Variable(y, requires_grad=False)\n        b_x = x.to(device)  # 將輸入數據移動到GPU上\n        b_y = y.to(device)  # 將標籤移動到GPU上\n        out = Densenet(b_x)\n        loss = loss_function(out, b_y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if step % 100 == 0:\n            print('Epoch: {} | Step: {} | Loss: {}'.format(epoch + 1, step, loss))\n\n# 容器來儲存每一輪的輸出\ntrain_predict = torch.Tensor().to(device)\ntrain_label = torch.Tensor().to(device)\ntest_predict = torch.Tensor().to(device)\ntest_label = torch.Tensor().to(device)\n\n\n# 在評估模式下，模型只需要在主 GPU 上執行\nDensenet = Densenet.module\n\nlocal_train_loader = copy.deepcopy(train_loader)\nlocal_test_loader = copy.deepcopy(test_loader)\n# 測試集\nDensenet.eval()  # 切換到評估模式\nmodel_path = '/kaggle/working/'\ntorch.save(Densenet.state_dict(), model_path+'Densenet.pth')\n\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_train_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Densenet(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        train_predict = torch.cat((train_predict, out), dim=0)\n        train_label = torch.cat((train_label, b_y), dim=0)\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_test_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Densenet(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        test_predict = torch.cat((test_predict, out), dim=0)\n        test_label = torch.cat((test_label, b_y), dim=0)\n\n# train_predict、train_label 分別包含了每一輪的模型訓練集預測和標籤\n# test_predict、test_label 分別包含了模型對測試集的預測和標籤\nprint(\"Shape of train_predict:\", train_predict.shape)\nprint(\"Shape of train_label:\", train_label.shape)\nprint(\"Shape of test_predict:\", test_predict.shape)\nprint(\"Shape of test_label:\", test_label.shape)\n\n\noutput_path = OUTPUT_PATH+'train'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':train_predict,'labelVectors':train_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Densenet_train_prediction.pt'))\n\n\noutput_path = OUTPUT_PATH+'test'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':test_predict,'labelVectors':test_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Densenet_test_prediction.pt'))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ResNet","metadata":{"id":"J4E9HFYFVOO2"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nimport copy\nimport os\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:39:54.279510Z","iopub.execute_input":"2023-12-10T01:39:54.280079Z","iopub.status.idle":"2023-12-10T01:39:54.290074Z","shell.execute_reply.started":"2023-12-10T01:39:54.280041Z","shell.execute_reply":"2023-12-10T01:39:54.289270Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport math\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    \"3x3 convolution with padding\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, depth, num_classes=45, block_name='BasicBlock'):\n        super(ResNet, self).__init__()\n        # Model type specifies number of layers for CIFAR-10 model\n        if block_name.lower() == 'basicblock':\n            assert (depth - 2) % 6 == 0, 'When use basicblock, depth should be 6n+2, e.g. 20, 32, 44, 56, 110, 1202'\n            n = (depth - 2) // 6\n            block = BasicBlock\n        elif block_name.lower() == 'bottleneck':\n            assert (depth - 2) % 9 == 0, 'When use bottleneck, depth should be 9n+2, e.g. 20, 29, 47, 56, 110, 1199'\n            n = (depth - 2) // 9\n            block = Bottleneck\n        else:\n            raise ValueError('block_name shoule be Basicblock or Bottleneck')\n\n\n        self.inplanes = 16\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(block, 16, n)\n        self.layer2 = self._make_layer(block, 32, n, stride=2)\n        self.layer3 = self._make_layer(block, 64, n, stride=2)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(64 * block.expansion * 64, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)    # 32x32\n\n        x = self.layer1(x)  # 32x32\n        x = self.layer2(x)  # 16x16\n        x = self.layer3(x)  # 8x8\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef resnet(**kwargs):\n    '''\n    Constructs a ResNet model.\n    '''\n    return ResNet(**kwargs)","metadata":{"id":"An53eKng9E4y","execution":{"iopub.status.busy":"2023-12-10T01:39:54.291238Z","iopub.execute_input":"2023-12-10T01:39:54.291624Z","iopub.status.idle":"2023-12-10T01:39:54.319619Z","shell.execute_reply.started":"2023-12-10T01:39:54.291598Z","shell.execute_reply":"2023-12-10T01:39:54.318728Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n\nResnet_20 = resnet(depth=20).cuda()\n# 使用 DataParallel 將模型複製到多個 GPU\nResnet_20 = nn.DataParallel(Resnet_20)\n\noptimizer = torch.optim.Adam(Resnet_20.parameters(), lr=LR)\nloss_function = nn.CrossEntropyLoss()\nlocal_train_data = copy.deepcopy(train_loader)\n\nfor epoch in range(EPOCH):\n    Resnet_20.train()\n    for step, (x, y) in enumerate(local_train_data):\n        # b_x = Variable(x, requires_grad=False)\n        # b_y = Variable(y, requires_grad=False)\n        b_x = x.to(device)  # 將輸入數據移動到GPU上\n        b_y = y.to(device)  # 將標籤移動到GPU上\n        out = Resnet_20(b_x)\n        loss = loss_function(out, b_y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if step % 100 == 0:\n            print('Epoch: {} | Step: {} | Loss: {}'.format(epoch + 1, step, loss))\n            \n            \n# 容器來儲存每一輪的輸出\ntrain_predict = torch.Tensor().to(device)\ntrain_label = torch.Tensor().to(device)\ntest_predict = torch.Tensor().to(device)\ntest_label = torch.Tensor().to(device)\n\n# 在評估模式下，模型只需要在主 GPU 上執行\nResnet_20 = Resnet_20.module\n\nlocal_train_loader = copy.deepcopy(train_loader)\nlocal_test_loader = copy.deepcopy(test_loader)\n# 測試集\nResnet_20.eval()  # 切換到評估模式\nmodel_path = '/kaggle/working/'\ntorch.save(Resnet_20.state_dict(), model_path+'Resnet_20.pth')\n\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_train_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Resnet_20(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        train_predict = torch.cat((train_predict, out), dim=0)\n        train_label = torch.cat((train_label, b_y), dim=0)\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_test_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Resnet_20(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        test_predict = torch.cat((test_predict, out), dim=0)\n        test_label = torch.cat((test_label, b_y), dim=0)\n        \n\n# train_predict、train_label 分別包含了每一輪的模型訓練集預測和標籤\n# test_predict、test_label 分別包含了模型對測試集的預測和標籤\nprint(\"Shape of train_predict:\", train_predict.shape)\nprint(\"Shape of train_label:\", train_label.shape)\nprint(\"Shape of test_predict:\", test_predict.shape)\nprint(\"Shape of test_label:\", test_label.shape)\n\n\noutput_path = OUTPUT_PATH+'train'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':train_predict,'labelVectors':train_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Resnet_20.pt'))\n\n\noutput_path = OUTPUT_PATH+'test'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':test_predict,'labelVectors':test_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Resnet_20.pt'))","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:39:54.320929Z","iopub.execute_input":"2023-12-10T01:39:54.321256Z","iopub.status.idle":"2023-12-10T01:39:54.335505Z","shell.execute_reply.started":"2023-12-10T01:39:54.321225Z","shell.execute_reply":"2023-12-10T01:39:54.334663Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'\\nimport torch\\ntorch.cuda.empty_cache()\\n\\nResnet_20 = resnet(depth=20).cuda()\\n# 使用 DataParallel 將模型複製到多個 GPU\\nResnet_20 = nn.DataParallel(Resnet_20)\\n\\noptimizer = torch.optim.Adam(Resnet_20.parameters(), lr=LR)\\nloss_function = nn.CrossEntropyLoss()\\nlocal_train_data = copy.deepcopy(train_loader)\\n\\nfor epoch in range(EPOCH):\\n    Resnet_20.train()\\n    for step, (x, y) in enumerate(local_train_data):\\n        # b_x = Variable(x, requires_grad=False)\\n        # b_y = Variable(y, requires_grad=False)\\n        b_x = x.to(device)  # 將輸入數據移動到GPU上\\n        b_y = y.to(device)  # 將標籤移動到GPU上\\n        out = Resnet_20(b_x)\\n        loss = loss_function(out, b_y)\\n\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n\\n        if step % 100 == 0:\\n            print(\\'Epoch: {} | Step: {} | Loss: {}\\'.format(epoch + 1, step, loss))\\n            \\n            \\n# 容器來儲存每一輪的輸出\\ntrain_predict = torch.Tensor().to(device)\\ntrain_label = torch.Tensor().to(device)\\ntest_predict = torch.Tensor().to(device)\\ntest_label = torch.Tensor().to(device)\\n\\n# 在評估模式下，模型只需要在主 GPU 上執行\\nResnet_20 = Resnet_20.module\\n\\nlocal_train_loader = copy.deepcopy(train_loader)\\nlocal_test_loader = copy.deepcopy(test_loader)\\n# 測試集\\nResnet_20.eval()  # 切換到評估模式\\nmodel_path = \\'/kaggle/working/\\'\\ntorch.save(Resnet_20.state_dict(), model_path+\\'Resnet_20.pth\\')\\n\\n\\nwith torch.no_grad():  # 在評估模式下，不計算梯度\\n    for step, (x, y) in enumerate(local_train_loader):\\n        b_x = x.to(device)\\n        b_y = y.to(device)\\n        out = Resnet_20(b_x)\\n        # 將該批次的預測結果和標籤添加到對應的容器中\\n        train_predict = torch.cat((train_predict, out), dim=0)\\n        train_label = torch.cat((train_label, b_y), dim=0)\\n\\nwith torch.no_grad():  # 在評估模式下，不計算梯度\\n    for step, (x, y) in enumerate(local_test_loader):\\n        b_x = x.to(device)\\n        b_y = y.to(device)\\n        out = Resnet_20(b_x)\\n        # 將該批次的預測結果和標籤添加到對應的容器中\\n        test_predict = torch.cat((test_predict, out), dim=0)\\n        test_label = torch.cat((test_label, b_y), dim=0)\\n        \\n\\n# train_predict、train_label 分別包含了每一輪的模型訓練集預測和標籤\\n# test_predict、test_label 分別包含了模型對測試集的預測和標籤\\nprint(\"Shape of train_predict:\", train_predict.shape)\\nprint(\"Shape of train_label:\", train_label.shape)\\nprint(\"Shape of test_predict:\", test_predict.shape)\\nprint(\"Shape of test_label:\", test_label.shape)\\n\\n\\noutput_path = OUTPUT_PATH+\\'train\\'\\nif not os.path.exists(output_path):\\n    os.mkdir(output_path)\\ntemp_dict = {\\'predictionVectors\\':train_predict,\\'labelVectors\\':train_label}\\ntorch.save(temp_dict, os.path.join(output_path, \\'Resnet_20.pt\\'))\\n\\n\\noutput_path = OUTPUT_PATH+\\'test\\'\\nif not os.path.exists(output_path):\\n    os.mkdir(output_path)\\ntemp_dict = {\\'predictionVectors\\':test_predict,\\'labelVectors\\':test_label}\\ntorch.save(temp_dict, os.path.join(output_path, \\'Resnet_20.pt\\'))\\n'"},"metadata":{}}]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n\nResnet_32 = resnet(depth=32).cuda()\n# 使用 DataParallel 將模型複製到多個 GPU\nResnet_32 = nn.DataParallel(Resnet_32)\n\noptimizer = torch.optim.Adam(Resnet_32.parameters(), lr=LR)\nloss_function = nn.CrossEntropyLoss()\nlocal_train_data = copy.deepcopy(train_loader)\n\nfor epoch in range(EPOCH):\n    Resnet_32.train()\n    for step, (x, y) in enumerate(local_train_data):\n        # b_x = Variable(x, requires_grad=False)\n        # b_y = Variable(y, requires_grad=False)\n        b_x = x.to(device)  # 將輸入數據移動到GPU上\n        b_y = y.to(device)  # 將標籤移動到GPU上\n        out = Resnet_32(b_x)\n        loss = loss_function(out, b_y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if step % 100 == 0:\n            print('Epoch: {} | Step: {} | Loss: {}'.format(epoch + 1, step, loss))\n            \n            \n# 容器來儲存每一輪的輸出\ntrain_predict = torch.Tensor().to(device)\ntrain_label = torch.Tensor().to(device)\ntest_predict = torch.Tensor().to(device)\ntest_label = torch.Tensor().to(device)\n\n# 在評估模式下，模型只需要在主 GPU 上執行\nResnet_32 = Resnet_32.module\n\nlocal_train_loader = copy.deepcopy(train_loader)\nlocal_test_loader = copy.deepcopy(test_loader)\n# 測試集\nResnet_32.eval()  # 切換到評估模式\nmodel_path = '/kaggle/working/'\ntorch.save(Resnet_32.state_dict(), model_path+'Resnet_32.pth')\n\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_train_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Resnet_32(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        train_predict = torch.cat((train_predict, out), dim=0)\n        train_label = torch.cat((train_label, b_y), dim=0)\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_test_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Resnet_32(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        test_predict = torch.cat((test_predict, out), dim=0)\n        test_label = torch.cat((test_label, b_y), dim=0)\n\n# train_predict、train_label 分別包含了每一輪的模型訓練集預測和標籤\n# test_predict、test_label 分別包含了模型對測試集的預測和標籤\nprint(\"Shape of train_predict:\", train_predict.shape)\nprint(\"Shape of train_label:\", train_label.shape)\nprint(\"Shape of test_predict:\", test_predict.shape)\nprint(\"Shape of test_label:\", test_label.shape)\n\n\noutput_path = OUTPUT_PATH+'train'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':train_predict,'labelVectors':train_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Resnet_32.pt'))\n\n\noutput_path = OUTPUT_PATH+'test'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':test_predict,'labelVectors':test_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Resnet_32.pt'))","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:39:54.336903Z","iopub.execute_input":"2023-12-10T01:39:54.337163Z","iopub.status.idle":"2023-12-10T01:39:54.350967Z","shell.execute_reply.started":"2023-12-10T01:39:54.337140Z","shell.execute_reply":"2023-12-10T01:39:54.350119Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'\\nimport torch\\ntorch.cuda.empty_cache()\\n\\nResnet_32 = resnet(depth=32).cuda()\\n# 使用 DataParallel 將模型複製到多個 GPU\\nResnet_32 = nn.DataParallel(Resnet_32)\\n\\noptimizer = torch.optim.Adam(Resnet_32.parameters(), lr=LR)\\nloss_function = nn.CrossEntropyLoss()\\nlocal_train_data = copy.deepcopy(train_loader)\\n\\nfor epoch in range(EPOCH):\\n    Resnet_32.train()\\n    for step, (x, y) in enumerate(local_train_data):\\n        # b_x = Variable(x, requires_grad=False)\\n        # b_y = Variable(y, requires_grad=False)\\n        b_x = x.to(device)  # 將輸入數據移動到GPU上\\n        b_y = y.to(device)  # 將標籤移動到GPU上\\n        out = Resnet_32(b_x)\\n        loss = loss_function(out, b_y)\\n\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n\\n        if step % 100 == 0:\\n            print(\\'Epoch: {} | Step: {} | Loss: {}\\'.format(epoch + 1, step, loss))\\n            \\n            \\n# 容器來儲存每一輪的輸出\\ntrain_predict = torch.Tensor().to(device)\\ntrain_label = torch.Tensor().to(device)\\ntest_predict = torch.Tensor().to(device)\\ntest_label = torch.Tensor().to(device)\\n\\n# 在評估模式下，模型只需要在主 GPU 上執行\\nResnet_32 = Resnet_32.module\\n\\nlocal_train_loader = copy.deepcopy(train_loader)\\nlocal_test_loader = copy.deepcopy(test_loader)\\n# 測試集\\nResnet_32.eval()  # 切換到評估模式\\nmodel_path = \\'/kaggle/working/\\'\\ntorch.save(Resnet_32.state_dict(), model_path+\\'Resnet_32.pth\\')\\n\\n\\nwith torch.no_grad():  # 在評估模式下，不計算梯度\\n    for step, (x, y) in enumerate(local_train_loader):\\n        b_x = x.to(device)\\n        b_y = y.to(device)\\n        out = Resnet_32(b_x)\\n        # 將該批次的預測結果和標籤添加到對應的容器中\\n        train_predict = torch.cat((train_predict, out), dim=0)\\n        train_label = torch.cat((train_label, b_y), dim=0)\\n\\nwith torch.no_grad():  # 在評估模式下，不計算梯度\\n    for step, (x, y) in enumerate(local_test_loader):\\n        b_x = x.to(device)\\n        b_y = y.to(device)\\n        out = Resnet_32(b_x)\\n        # 將該批次的預測結果和標籤添加到對應的容器中\\n        test_predict = torch.cat((test_predict, out), dim=0)\\n        test_label = torch.cat((test_label, b_y), dim=0)\\n\\n# train_predict、train_label 分別包含了每一輪的模型訓練集預測和標籤\\n# test_predict、test_label 分別包含了模型對測試集的預測和標籤\\nprint(\"Shape of train_predict:\", train_predict.shape)\\nprint(\"Shape of train_label:\", train_label.shape)\\nprint(\"Shape of test_predict:\", test_predict.shape)\\nprint(\"Shape of test_label:\", test_label.shape)\\n\\n\\noutput_path = OUTPUT_PATH+\\'train\\'\\nif not os.path.exists(output_path):\\n    os.mkdir(output_path)\\ntemp_dict = {\\'predictionVectors\\':train_predict,\\'labelVectors\\':train_label}\\ntorch.save(temp_dict, os.path.join(output_path, \\'Resnet_32.pt\\'))\\n\\n\\noutput_path = OUTPUT_PATH+\\'test\\'\\nif not os.path.exists(output_path):\\n    os.mkdir(output_path)\\ntemp_dict = {\\'predictionVectors\\':test_predict,\\'labelVectors\\':test_label}\\ntorch.save(temp_dict, os.path.join(output_path, \\'Resnet_32.pt\\'))\\n'"},"metadata":{}}]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n\nResnet_44 = resnet(depth=44).cuda()\n# 使用 DataParallel 將模型複製到多個 GPU\nResnet_44 = nn.DataParallel(Resnet_44)\n\noptimizer = torch.optim.Adam(Resnet_44.parameters(), lr=LR)\nloss_function = nn.CrossEntropyLoss()\nlocal_train_data = copy.deepcopy(train_loader)\n\nfor epoch in range(EPOCH):\n    Resnet_44.train()\n    for step, (x, y) in enumerate(local_train_data):\n        # b_x = Variable(x, requires_grad=False)\n        # b_y = Variable(y, requires_grad=False)\n        b_x = x.to(device)  # 將輸入數據移動到GPU上\n        b_y = y.to(device)  # 將標籤移動到GPU上\n        out = Resnet_44(b_x)\n        loss = loss_function(out, b_y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if step % 100 == 0:\n            print('Epoch: {} | Step: {} | Loss: {}'.format(epoch + 1, step, loss))\n            \n            \n# 容器來儲存每一輪的輸出\ntrain_predict = torch.Tensor().to(device)\ntrain_label = torch.Tensor().to(device)\ntest_predict = torch.Tensor().to(device)\ntest_label = torch.Tensor().to(device)\n\n# 在評估模式下，模型只需要在主 GPU 上執行\nResnet_44 = Resnet_44.module\n\nlocal_train_loader = copy.deepcopy(train_loader)\nlocal_test_loader = copy.deepcopy(test_loader)\n# 測試集\nResnet_44.eval()  # 切換到評估模式\nmodel_path = '/kaggle/working/'\ntorch.save(Resnet_44.state_dict(), model_path+'Resnet_44.pth')\n\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_train_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Resnet_44(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        train_predict = torch.cat((train_predict, out), dim=0)\n        train_label = torch.cat((train_label, b_y), dim=0)\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_test_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Resnet_44(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        test_predict = torch.cat((test_predict, out), dim=0)\n        test_label = torch.cat((test_label, b_y), dim=0)\n\n# train_predict、train_label 分別包含了每一輪的模型訓練集預測和標籤\n# test_predict、test_label 分別包含了模型對測試集的預測和標籤\nprint(\"Shape of train_predict:\", train_predict.shape)\nprint(\"Shape of train_label:\", train_label.shape)\nprint(\"Shape of test_predict:\", test_predict.shape)\nprint(\"Shape of test_label:\", test_label.shape)\n\n\noutput_path = OUTPUT_PATH+'train'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':train_predict,'labelVectors':train_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Resnet_44.pt'))\n\n\noutput_path = OUTPUT_PATH+'test'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':test_predict,'labelVectors':test_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Resnet_44.pt'))","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:39:54.352128Z","iopub.execute_input":"2023-12-10T01:39:54.352406Z","iopub.status.idle":"2023-12-10T01:39:54.368332Z","shell.execute_reply.started":"2023-12-10T01:39:54.352378Z","shell.execute_reply":"2023-12-10T01:39:54.367471Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'\\nimport torch\\ntorch.cuda.empty_cache()\\n\\nResnet_44 = resnet(depth=44).cuda()\\n# 使用 DataParallel 將模型複製到多個 GPU\\nResnet_44 = nn.DataParallel(Resnet_44)\\n\\noptimizer = torch.optim.Adam(Resnet_44.parameters(), lr=LR)\\nloss_function = nn.CrossEntropyLoss()\\nlocal_train_data = copy.deepcopy(train_loader)\\n\\nfor epoch in range(EPOCH):\\n    Resnet_44.train()\\n    for step, (x, y) in enumerate(local_train_data):\\n        # b_x = Variable(x, requires_grad=False)\\n        # b_y = Variable(y, requires_grad=False)\\n        b_x = x.to(device)  # 將輸入數據移動到GPU上\\n        b_y = y.to(device)  # 將標籤移動到GPU上\\n        out = Resnet_44(b_x)\\n        loss = loss_function(out, b_y)\\n\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n\\n        if step % 100 == 0:\\n            print(\\'Epoch: {} | Step: {} | Loss: {}\\'.format(epoch + 1, step, loss))\\n            \\n            \\n# 容器來儲存每一輪的輸出\\ntrain_predict = torch.Tensor().to(device)\\ntrain_label = torch.Tensor().to(device)\\ntest_predict = torch.Tensor().to(device)\\ntest_label = torch.Tensor().to(device)\\n\\n# 在評估模式下，模型只需要在主 GPU 上執行\\nResnet_44 = Resnet_44.module\\n\\nlocal_train_loader = copy.deepcopy(train_loader)\\nlocal_test_loader = copy.deepcopy(test_loader)\\n# 測試集\\nResnet_44.eval()  # 切換到評估模式\\nmodel_path = \\'/kaggle/working/\\'\\ntorch.save(Resnet_44.state_dict(), model_path+\\'Resnet_44.pth\\')\\n\\n\\nwith torch.no_grad():  # 在評估模式下，不計算梯度\\n    for step, (x, y) in enumerate(local_train_loader):\\n        b_x = x.to(device)\\n        b_y = y.to(device)\\n        out = Resnet_44(b_x)\\n        # 將該批次的預測結果和標籤添加到對應的容器中\\n        train_predict = torch.cat((train_predict, out), dim=0)\\n        train_label = torch.cat((train_label, b_y), dim=0)\\n\\nwith torch.no_grad():  # 在評估模式下，不計算梯度\\n    for step, (x, y) in enumerate(local_test_loader):\\n        b_x = x.to(device)\\n        b_y = y.to(device)\\n        out = Resnet_44(b_x)\\n        # 將該批次的預測結果和標籤添加到對應的容器中\\n        test_predict = torch.cat((test_predict, out), dim=0)\\n        test_label = torch.cat((test_label, b_y), dim=0)\\n\\n# train_predict、train_label 分別包含了每一輪的模型訓練集預測和標籤\\n# test_predict、test_label 分別包含了模型對測試集的預測和標籤\\nprint(\"Shape of train_predict:\", train_predict.shape)\\nprint(\"Shape of train_label:\", train_label.shape)\\nprint(\"Shape of test_predict:\", test_predict.shape)\\nprint(\"Shape of test_label:\", test_label.shape)\\n\\n\\noutput_path = OUTPUT_PATH+\\'train\\'\\nif not os.path.exists(output_path):\\n    os.mkdir(output_path)\\ntemp_dict = {\\'predictionVectors\\':train_predict,\\'labelVectors\\':train_label}\\ntorch.save(temp_dict, os.path.join(output_path, \\'Resnet_44.pt\\'))\\n\\n\\noutput_path = OUTPUT_PATH+\\'test\\'\\nif not os.path.exists(output_path):\\n    os.mkdir(output_path)\\ntemp_dict = {\\'predictionVectors\\':test_predict,\\'labelVectors\\':test_label}\\ntorch.save(temp_dict, os.path.join(output_path, \\'Resnet_44.pt\\'))\\n'"},"metadata":{}}]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n\nResnet_56 = resnet(depth=56).cuda()\n# 使用 DataParallel 將模型複製到多個 GPU\nResnet_56 = nn.DataParallel(Resnet_56)\n\noptimizer = torch.optim.Adam(Resnet_56.parameters(), lr=LR)\nloss_function = nn.CrossEntropyLoss()\nlocal_train_data = copy.deepcopy(train_loader)\n\nfor epoch in range(EPOCH):\n    Resnet_56.train()\n    for step, (x, y) in enumerate(local_train_data):\n        # b_x = Variable(x, requires_grad=False)\n        # b_y = Variable(y, requires_grad=False)\n        b_x = x.to(device)  # 將輸入數據移動到GPU上\n        b_y = y.to(device)  # 將標籤移動到GPU上\n        out = Resnet_56(b_x)\n        loss = loss_function(out, b_y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if step % 100 == 0:\n            print('Epoch: {} | Step: {} | Loss: {}'.format(epoch + 1, step, loss))\n            \n            \n# 容器來儲存每一輪的輸出\ntrain_predict = torch.Tensor().to(device)\ntrain_label = torch.Tensor().to(device)\ntest_predict = torch.Tensor().to(device)\ntest_label = torch.Tensor().to(device)\n\n# 在評估模式下，模型只需要在主 GPU 上執行\nResnet_56 = Resnet_56.module\n\nlocal_train_loader = copy.deepcopy(train_loader)\nlocal_test_loader = copy.deepcopy(test_loader)\n# 測試集\nResnet_56.eval()  # 切換到評估模式\nmodel_path = '/kaggle/working/'\ntorch.save(Resnet_56.state_dict(), model_path+'Resnet_56.pth')\n\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_train_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Resnet_56(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        train_predict = torch.cat((train_predict, out), dim=0)\n        train_label = torch.cat((train_label, b_y), dim=0)\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_test_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Resnet_56(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        test_predict = torch.cat((test_predict, out), dim=0)\n        test_label = torch.cat((test_label, b_y), dim=0)\n\n# train_predict、train_label 分別包含了每一輪的模型訓練集預測和標籤\n# test_predict、test_label 分別包含了模型對測試集的預測和標籤\nprint(\"Shape of train_predict:\", train_predict.shape)\nprint(\"Shape of train_label:\", train_label.shape)\nprint(\"Shape of test_predict:\", test_predict.shape)\nprint(\"Shape of test_label:\", test_label.shape)\n\n\noutput_path = OUTPUT_PATH+'train'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':train_predict,'labelVectors':train_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Resnet_56.pt'))\n\n\noutput_path = OUTPUT_PATH+'test'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':test_predict,'labelVectors':test_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Resnet_56.pt'))","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:39:54.369560Z","iopub.execute_input":"2023-12-10T01:39:54.369850Z","iopub.status.idle":"2023-12-10T01:39:54.383532Z","shell.execute_reply.started":"2023-12-10T01:39:54.369816Z","shell.execute_reply":"2023-12-10T01:39:54.382674Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'\\nimport torch\\ntorch.cuda.empty_cache()\\n\\nResnet_56 = resnet(depth=56).cuda()\\n# 使用 DataParallel 將模型複製到多個 GPU\\nResnet_56 = nn.DataParallel(Resnet_56)\\n\\noptimizer = torch.optim.Adam(Resnet_56.parameters(), lr=LR)\\nloss_function = nn.CrossEntropyLoss()\\nlocal_train_data = copy.deepcopy(train_loader)\\n\\nfor epoch in range(EPOCH):\\n    Resnet_56.train()\\n    for step, (x, y) in enumerate(local_train_data):\\n        # b_x = Variable(x, requires_grad=False)\\n        # b_y = Variable(y, requires_grad=False)\\n        b_x = x.to(device)  # 將輸入數據移動到GPU上\\n        b_y = y.to(device)  # 將標籤移動到GPU上\\n        out = Resnet_56(b_x)\\n        loss = loss_function(out, b_y)\\n\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n\\n        if step % 100 == 0:\\n            print(\\'Epoch: {} | Step: {} | Loss: {}\\'.format(epoch + 1, step, loss))\\n            \\n            \\n# 容器來儲存每一輪的輸出\\ntrain_predict = torch.Tensor().to(device)\\ntrain_label = torch.Tensor().to(device)\\ntest_predict = torch.Tensor().to(device)\\ntest_label = torch.Tensor().to(device)\\n\\n# 在評估模式下，模型只需要在主 GPU 上執行\\nResnet_56 = Resnet_56.module\\n\\nlocal_train_loader = copy.deepcopy(train_loader)\\nlocal_test_loader = copy.deepcopy(test_loader)\\n# 測試集\\nResnet_56.eval()  # 切換到評估模式\\nmodel_path = \\'/kaggle/working/\\'\\ntorch.save(Resnet_56.state_dict(), model_path+\\'Resnet_56.pth\\')\\n\\n\\nwith torch.no_grad():  # 在評估模式下，不計算梯度\\n    for step, (x, y) in enumerate(local_train_loader):\\n        b_x = x.to(device)\\n        b_y = y.to(device)\\n        out = Resnet_56(b_x)\\n        # 將該批次的預測結果和標籤添加到對應的容器中\\n        train_predict = torch.cat((train_predict, out), dim=0)\\n        train_label = torch.cat((train_label, b_y), dim=0)\\n\\nwith torch.no_grad():  # 在評估模式下，不計算梯度\\n    for step, (x, y) in enumerate(local_test_loader):\\n        b_x = x.to(device)\\n        b_y = y.to(device)\\n        out = Resnet_56(b_x)\\n        # 將該批次的預測結果和標籤添加到對應的容器中\\n        test_predict = torch.cat((test_predict, out), dim=0)\\n        test_label = torch.cat((test_label, b_y), dim=0)\\n\\n# train_predict、train_label 分別包含了每一輪的模型訓練集預測和標籤\\n# test_predict、test_label 分別包含了模型對測試集的預測和標籤\\nprint(\"Shape of train_predict:\", train_predict.shape)\\nprint(\"Shape of train_label:\", train_label.shape)\\nprint(\"Shape of test_predict:\", test_predict.shape)\\nprint(\"Shape of test_label:\", test_label.shape)\\n\\n\\noutput_path = OUTPUT_PATH+\\'train\\'\\nif not os.path.exists(output_path):\\n    os.mkdir(output_path)\\ntemp_dict = {\\'predictionVectors\\':train_predict,\\'labelVectors\\':train_label}\\ntorch.save(temp_dict, os.path.join(output_path, \\'Resnet_56.pt\\'))\\n\\n\\noutput_path = OUTPUT_PATH+\\'test\\'\\nif not os.path.exists(output_path):\\n    os.mkdir(output_path)\\ntemp_dict = {\\'predictionVectors\\':test_predict,\\'labelVectors\\':test_label}\\ntorch.save(temp_dict, os.path.join(output_path, \\'Resnet_56.pt\\'))\\n'"},"metadata":{}}]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n\nResnet_110 = resnet(depth=110).cuda()\n# 使用 DataParallel 將模型複製到多個 GPU\nResnet_110 = nn.DataParallel(Resnet_110)\n\noptimizer = torch.optim.Adam(Resnet_110.parameters(), lr=LR)\nloss_function = nn.CrossEntropyLoss()\nlocal_train_data = copy.deepcopy(train_loader)\n\nfor epoch in range(EPOCH):\n    Resnet_110.train()\n    for step, (x, y) in enumerate(local_train_data):\n        # b_x = Variable(x, requires_grad=False)\n        # b_y = Variable(y, requires_grad=False)\n        b_x = x.to(device)  # 將輸入數據移動到GPU上\n        b_y = y.to(device)  # 將標籤移動到GPU上\n        out = Resnet_110(b_x)\n        loss = loss_function(out, b_y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if step % 100 == 0:\n            print('Epoch: {} | Step: {} | Loss: {}'.format(epoch + 1, step, loss))\n            \n            \n# 容器來儲存每一輪的輸出\ntrain_predict = torch.Tensor().to(device)\ntrain_label = torch.Tensor().to(device)\ntest_predict = torch.Tensor().to(device)\ntest_label = torch.Tensor().to(device)\n\n# 在評估模式下，模型只需要在主 GPU 上執行\nResnet_110 = Resnet_110.module\n\nlocal_train_loader = copy.deepcopy(train_loader)\nlocal_test_loader = copy.deepcopy(test_loader)\n# 測試集\nResnet_110.eval()  # 切換到評估模式\nmodel_path = '/kaggle/working/'\ntorch.save(Resnet_110.state_dict(), model_path+'Resnet_110.pth')\n\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_train_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Resnet_110(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        train_predict = torch.cat((train_predict, out), dim=0)\n        train_label = torch.cat((train_label, b_y), dim=0)\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_test_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Resnet_110(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        test_predict = torch.cat((test_predict, out), dim=0)\n        test_label = torch.cat((test_label, b_y), dim=0)\n\n# train_predict、train_label 分別包含了每一輪的模型訓練集預測和標籤\n# test_predict、test_label 分別包含了模型對測試集的預測和標籤\nprint(\"Shape of train_predict:\", train_predict.shape)\nprint(\"Shape of train_label:\", train_label.shape)\nprint(\"Shape of test_predict:\", test_predict.shape)\nprint(\"Shape of test_label:\", test_label.shape)\n\n\noutput_path = OUTPUT_PATH+'train'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':train_predict,'labelVectors':train_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Resnet_110_train_prediction.pt'))\n\n\noutput_path = OUTPUT_PATH+'test'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':test_predict,'labelVectors':test_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Resnet_110_test_prediction.pt'))","metadata":{"id":"mZv3ST309E2R","outputId":"d73dac29-c1a5-41a6-8010-d1c2dfb7ddde","execution":{"iopub.status.busy":"2023-12-10T01:39:54.384603Z","iopub.execute_input":"2023-12-10T01:39:54.384890Z","iopub.status.idle":"2023-12-10T04:29:58.131026Z","shell.execute_reply.started":"2023-12-10T01:39:54.384866Z","shell.execute_reply":"2023-12-10T04:29:58.129939Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch: 1 | Step: 0 | Loss: 5.28169584274292\nEpoch: 1 | Step: 100 | Loss: 3.9966320991516113\nEpoch: 1 | Step: 200 | Loss: 3.562718629837036\nEpoch: 1 | Step: 300 | Loss: 3.560755729675293\nEpoch: 2 | Step: 0 | Loss: 3.686568021774292\nEpoch: 2 | Step: 100 | Loss: 3.6070845127105713\nEpoch: 2 | Step: 200 | Loss: 3.5842502117156982\nEpoch: 2 | Step: 300 | Loss: 3.2494888305664062\nEpoch: 3 | Step: 0 | Loss: 3.6376397609710693\nEpoch: 3 | Step: 100 | Loss: 3.5706472396850586\nEpoch: 3 | Step: 200 | Loss: 3.512605667114258\nEpoch: 3 | Step: 300 | Loss: 3.2218384742736816\nEpoch: 4 | Step: 0 | Loss: 3.1068105697631836\nEpoch: 4 | Step: 100 | Loss: 3.218820095062256\nEpoch: 4 | Step: 200 | Loss: 3.097757339477539\nEpoch: 4 | Step: 300 | Loss: 3.131363868713379\nEpoch: 5 | Step: 0 | Loss: 2.756802558898926\nEpoch: 5 | Step: 100 | Loss: 3.28602933883667\nEpoch: 5 | Step: 200 | Loss: 2.690990924835205\nEpoch: 5 | Step: 300 | Loss: 3.3440909385681152\nEpoch: 6 | Step: 0 | Loss: 2.893430471420288\nEpoch: 6 | Step: 100 | Loss: 2.991334915161133\nEpoch: 6 | Step: 200 | Loss: 3.159569263458252\nEpoch: 6 | Step: 300 | Loss: 2.8116302490234375\nEpoch: 7 | Step: 0 | Loss: 3.4767937660217285\nEpoch: 7 | Step: 100 | Loss: 3.063934087753296\nEpoch: 7 | Step: 200 | Loss: 2.6043167114257812\nEpoch: 7 | Step: 300 | Loss: 2.9977941513061523\nEpoch: 8 | Step: 0 | Loss: 3.004349946975708\nEpoch: 8 | Step: 100 | Loss: 2.9078800678253174\nEpoch: 8 | Step: 200 | Loss: 3.0799880027770996\nEpoch: 8 | Step: 300 | Loss: 2.896409034729004\nEpoch: 9 | Step: 0 | Loss: 2.5043294429779053\nEpoch: 9 | Step: 100 | Loss: 2.6526377201080322\nEpoch: 9 | Step: 200 | Loss: 2.7206239700317383\nEpoch: 9 | Step: 300 | Loss: 2.425772190093994\nEpoch: 10 | Step: 0 | Loss: 2.5997204780578613\nEpoch: 10 | Step: 100 | Loss: 2.7118587493896484\nEpoch: 10 | Step: 200 | Loss: 2.7129976749420166\nEpoch: 10 | Step: 300 | Loss: 2.870971441268921\nEpoch: 11 | Step: 0 | Loss: 2.057948350906372\nEpoch: 11 | Step: 100 | Loss: 2.3688883781433105\nEpoch: 11 | Step: 200 | Loss: 2.590907096862793\nEpoch: 11 | Step: 300 | Loss: 2.300616502761841\nEpoch: 12 | Step: 0 | Loss: 2.447429895401001\nEpoch: 12 | Step: 100 | Loss: 2.5397636890411377\nEpoch: 12 | Step: 200 | Loss: 2.144033670425415\nEpoch: 12 | Step: 300 | Loss: 2.5671796798706055\nEpoch: 13 | Step: 0 | Loss: 2.2521846294403076\nEpoch: 13 | Step: 100 | Loss: 2.824683904647827\nEpoch: 13 | Step: 200 | Loss: 2.4039855003356934\nEpoch: 13 | Step: 300 | Loss: 2.2097291946411133\nEpoch: 14 | Step: 0 | Loss: 2.2415049076080322\nEpoch: 14 | Step: 100 | Loss: 2.6705644130706787\nEpoch: 14 | Step: 200 | Loss: 2.6548073291778564\nEpoch: 14 | Step: 300 | Loss: 1.875301718711853\nEpoch: 15 | Step: 0 | Loss: 2.318568468093872\nEpoch: 15 | Step: 100 | Loss: 1.81489098072052\nEpoch: 15 | Step: 200 | Loss: 2.240159273147583\nEpoch: 15 | Step: 300 | Loss: 2.5849618911743164\nEpoch: 16 | Step: 0 | Loss: 2.2231738567352295\nEpoch: 16 | Step: 100 | Loss: 2.556170701980591\nEpoch: 16 | Step: 200 | Loss: 2.4851176738739014\nEpoch: 16 | Step: 300 | Loss: 2.311239242553711\nEpoch: 17 | Step: 0 | Loss: 2.5730955600738525\nEpoch: 17 | Step: 100 | Loss: 2.092449903488159\nEpoch: 17 | Step: 200 | Loss: 2.0626444816589355\nEpoch: 17 | Step: 300 | Loss: 2.514204502105713\nEpoch: 18 | Step: 0 | Loss: 2.4562795162200928\nEpoch: 18 | Step: 100 | Loss: 2.018453598022461\nEpoch: 18 | Step: 200 | Loss: 2.4189445972442627\nEpoch: 18 | Step: 300 | Loss: 2.603281021118164\nEpoch: 19 | Step: 0 | Loss: 2.225602388381958\nEpoch: 19 | Step: 100 | Loss: 2.3865952491760254\nEpoch: 19 | Step: 200 | Loss: 2.5947623252868652\nEpoch: 19 | Step: 300 | Loss: 2.18080735206604\nEpoch: 20 | Step: 0 | Loss: 2.313648223876953\nEpoch: 20 | Step: 100 | Loss: 2.610400915145874\nEpoch: 20 | Step: 200 | Loss: 2.2830512523651123\nEpoch: 20 | Step: 300 | Loss: 1.982576608657837\nEpoch: 21 | Step: 0 | Loss: 1.8696658611297607\nEpoch: 21 | Step: 100 | Loss: 2.0984959602355957\nEpoch: 21 | Step: 200 | Loss: 2.4505615234375\nEpoch: 21 | Step: 300 | Loss: 1.871680736541748\nEpoch: 22 | Step: 0 | Loss: 2.0678153038024902\nEpoch: 22 | Step: 100 | Loss: 1.8992103338241577\nEpoch: 22 | Step: 200 | Loss: 2.0451900959014893\nEpoch: 22 | Step: 300 | Loss: 1.760515570640564\nEpoch: 23 | Step: 0 | Loss: 1.965417504310608\nEpoch: 23 | Step: 100 | Loss: 2.1892311573028564\nEpoch: 23 | Step: 200 | Loss: 1.6390094757080078\nEpoch: 23 | Step: 300 | Loss: 2.860506057739258\nEpoch: 24 | Step: 0 | Loss: 2.1190743446350098\nEpoch: 24 | Step: 100 | Loss: 2.034026622772217\nEpoch: 24 | Step: 200 | Loss: 2.1654465198516846\nEpoch: 24 | Step: 300 | Loss: 1.7183005809783936\nEpoch: 25 | Step: 0 | Loss: 1.4858542680740356\nEpoch: 25 | Step: 100 | Loss: 1.8082958459854126\nEpoch: 25 | Step: 200 | Loss: 2.185471296310425\nEpoch: 25 | Step: 300 | Loss: 1.9029349088668823\nEpoch: 26 | Step: 0 | Loss: 1.6850773096084595\nEpoch: 26 | Step: 100 | Loss: 1.430779218673706\nEpoch: 26 | Step: 200 | Loss: 1.965306282043457\nEpoch: 26 | Step: 300 | Loss: 2.0089409351348877\nEpoch: 27 | Step: 0 | Loss: 1.3510245084762573\nEpoch: 27 | Step: 100 | Loss: 1.920311689376831\nEpoch: 27 | Step: 200 | Loss: 1.4664936065673828\nEpoch: 27 | Step: 300 | Loss: 1.3889423608779907\nEpoch: 28 | Step: 0 | Loss: 1.956440806388855\nEpoch: 28 | Step: 100 | Loss: 1.793190598487854\nEpoch: 28 | Step: 200 | Loss: 1.726625680923462\nEpoch: 28 | Step: 300 | Loss: 1.8606525659561157\nEpoch: 29 | Step: 0 | Loss: 1.6775513887405396\nEpoch: 29 | Step: 100 | Loss: 2.0802688598632812\nEpoch: 29 | Step: 200 | Loss: 1.5572785139083862\nEpoch: 29 | Step: 300 | Loss: 1.9587223529815674\nEpoch: 30 | Step: 0 | Loss: 1.4977025985717773\nEpoch: 30 | Step: 100 | Loss: 1.2377849817276\nEpoch: 30 | Step: 200 | Loss: 1.9192516803741455\nEpoch: 30 | Step: 300 | Loss: 1.481154441833496\nShape of train_predict: torch.Size([9625, 45])\nShape of train_label: torch.Size([9625])\nShape of test_predict: torch.Size([2682, 45])\nShape of test_label: torch.Size([2682])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# VGG","metadata":{}},{"cell_type":"code","source":"'''VGG for CIFAR10. FC layers are removed.\n'''\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport math\n\n\n__all__ = [\n    'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n    'vgg19_bn', 'vgg19',\n]\n\n\nmodel_urls = {\n    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n}\n\n\nclass VGG(nn.Module):\n\n    def __init__(self, features, num_classes=45):\n        super(VGG, self).__init__()\n        self.features = features\n        self.classifier = nn.Linear(512*64, num_classes)\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                n = m.weight.size(1)\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for v in cfg:\n        if v == 'M':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)\n\n\ncfg = {\n    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n}\n\n\ndef vgg11(**kwargs):\n    '''VGG 11-layer model (configuration \"A\")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    '''\n    model = VGG(make_layers(cfg['A']), **kwargs)\n    return model\n\n\ndef vgg11_bn(**kwargs):\n    '''VGG 11-layer model (configuration \"A\") with batch normalization'''\n    model = VGG(make_layers(cfg['A'], batch_norm=True), **kwargs)\n    return model\n\n\ndef vgg13(**kwargs):\n    '''VGG 13-layer model (configuration \"B\")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    '''\n    model = VGG(make_layers(cfg['B']), **kwargs)\n    return model\n\n\ndef vgg13_bn(**kwargs):\n    '''VGG 13-layer model (configuration \"B\") with batch normalization'''\n    model = VGG(make_layers(cfg['B'], batch_norm=True), **kwargs)\n    return model\n\n\ndef vgg16(**kwargs):\n    '''VGG 16-layer model (configuration \"D\")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    '''\n    model = VGG(make_layers(cfg['D']), **kwargs)\n    return model\n\n\ndef vgg16_bn(**kwargs):\n    '''VGG 16-layer model (configuration \"D\") with batch normalization'''\n    model = VGG(make_layers(cfg['D'], batch_norm=True), **kwargs)\n    return model\n\n\ndef vgg19(**kwargs):\n    '''VGG 19-layer model (configuration \"E\")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    '''\n    model = VGG(make_layers(cfg['E']), **kwargs)\n    return model\n\n\ndef vgg19_bn(**kwargs):\n    '''VGG 19-layer model (configuration 'E') with batch normalization'''\n    model = VGG(make_layers(cfg['E'], batch_norm=True), **kwargs)\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n\nVgg16_bn = vgg16_bn().cuda()\n\nVgg16_bn = nn.DataParallel(Vgg16_bn)\n\noptimizer = torch.optim.Adam(Vgg16_bn.parameters(), lr=LR)\nloss_function = nn.CrossEntropyLoss()\nlocal_train_data = copy.deepcopy(train_loader)\n\nfor epoch in range(EPOCH):\n    Vgg16_bn.train()\n    for step, (x, y) in enumerate(local_train_data):\n        # b_x = Variable(x, requires_grad=False)\n        # b_y = Variable(y, requires_grad=False)\n        b_x = x.to(device)  # 將輸入數據移動到GPU上\n        b_y = y.to(device)  # 將標籤移動到GPU上\n        out = Vgg16_bn(b_x)\n        loss = loss_function(out, b_y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if step % 100 == 0:\n            print('Epoch: {} | Step: {} | Loss: {}'.format(epoch + 1, step, loss))\n\n# 容器來儲存每一輪的輸出\ntrain_predict = torch.Tensor().to(device)\ntrain_label = torch.Tensor().to(device)\ntest_predict = torch.Tensor().to(device)\ntest_label = torch.Tensor().to(device)\n\n\n# 在評估模式下，模型只需要在主 GPU 上執行\nVgg16_bn = Vgg16_bn.module\n\nlocal_train_loader = copy.deepcopy(train_loader)\nlocal_test_loader = copy.deepcopy(test_loader)\n# 測試集\nVgg16_bn.eval()  # 切換到評估模式\nmodel_path = '/kaggle/working/'\ntorch.save(Vgg16_bn.state_dict(), model_path+'Vgg16_bn.pth')\n\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_train_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Vgg16_bn(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        train_predict = torch.cat((train_predict, out), dim=0)\n        train_label = torch.cat((train_label, b_y), dim=0)\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_test_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Vgg16_bn(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        test_predict = torch.cat((test_predict, out), dim=0)\n        test_label = torch.cat((test_label, b_y), dim=0)\n\n# train_predict、train_label 分別包含了每一輪的模型訓練集預測和標籤\n# test_predict、test_label 分別包含了模型對測試集的預測和標籤\nprint(\"Shape of train_predict:\", train_predict.shape)\nprint(\"Shape of train_label:\", train_label.shape)\nprint(\"Shape of test_predict:\", test_predict.shape)\nprint(\"Shape of test_label:\", test_label.shape)\n\n\noutput_path = OUTPUT_PATH+'train'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':train_predict,'labelVectors':train_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Vgg16_bn_train_prediction.pt'))\n\n\noutput_path = OUTPUT_PATH+'test'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':test_predict,'labelVectors':test_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Vgg16_bn_test_prediction.pt'))            ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n\nVgg19_bn = vgg19_bn().cuda()\n\nVgg19_bn = nn.DataParallel(Vgg19_bn)\noptimizer = torch.optim.Adam(Vgg19_bn.parameters(), lr=LR)\nloss_function = nn.CrossEntropyLoss()\nlocal_train_data = copy.deepcopy(train_loader)\n\nfor epoch in range(EPOCH):\n    Vgg19_bn.train()\n    for step, (x, y) in enumerate(local_train_data):\n        # b_x = Variable(x, requires_grad=False)\n        # b_y = Variable(y, requires_grad=False)\n        b_x = x.to(device)  # 將輸入數據移動到GPU上\n        b_y = y.to(device)  # 將標籤移動到GPU上\n        out = Vgg19_bn(b_x)\n        loss = loss_function(out, b_y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if step % 100 == 0:\n            print('Epoch: {} | Step: {} | Loss: {}'.format(epoch + 1, step, loss))\n\n\n# 容器來儲存每一輪的輸出\ntrain_predict = torch.Tensor().to(device)\ntrain_label = torch.Tensor().to(device)\ntest_predict = torch.Tensor().to(device)\ntest_label = torch.Tensor().to(device)\n\n\n# 在評估模式下，模型只需要在主 GPU 上執行\nVgg19_bn = Vgg19_bn.module\n\nlocal_train_loader = copy.deepcopy(train_loader)\nlocal_test_loader = copy.deepcopy(test_loader)\n# 測試集\nVgg19_bn.eval()  # 切換到評估模式\nmodel_path = '/kaggle/working/'\ntorch.save(Vgg19_bn.state_dict(), model_path+'Vgg19_bn.pth')\n\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_train_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Vgg19_bn(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        train_predict = torch.cat((train_predict, out), dim=0)\n        train_label = torch.cat((train_label, b_y), dim=0)\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_test_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Vgg19_bn(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        test_predict = torch.cat((test_predict, out), dim=0)\n        test_label = torch.cat((test_label, b_y), dim=0)\n\n# train_predict、train_label 分別包含了每一輪的模型訓練集預測和標籤\n# test_predict、test_label 分別包含了模型對測試集的預測和標籤\nprint(\"Shape of train_predict:\", train_predict.shape)\nprint(\"Shape of train_label:\", train_label.shape)\nprint(\"Shape of test_predict:\", test_predict.shape)\nprint(\"Shape of test_label:\", test_label.shape)\n\n\noutput_path = OUTPUT_PATH+'train'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':train_predict,'labelVectors':train_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Vgg19_bn_train_prediction.pt'))\n\n\noutput_path = OUTPUT_PATH+'test'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':test_predict,'labelVectors':test_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Vgg19_bn_test_prediction.pt'))      ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Wrn\n","metadata":{}},{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n        super(BasicBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.droprate = dropRate\n        self.equalInOut = (in_planes == out_planes)\n        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n                               padding=0, bias=False) or None\n    def forward(self, x):\n        if not self.equalInOut:\n            x = self.relu1(self.bn1(x))\n        else:\n            out = self.relu1(self.bn1(x))\n        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, training=self.training)\n        out = self.conv2(out)\n        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n\nclass NetworkBlock(nn.Module):\n    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n        super(NetworkBlock, self).__init__()\n        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n        layers = []\n        for i in range(nb_layers):\n            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n        return nn.Sequential(*layers)\n    def forward(self, x):\n        return self.layer(x)\n\nclass WideResNet(nn.Module):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n        super(WideResNet, self).__init__()\n        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n        assert (depth - 4) % 6 == 0, 'depth should be 6n+4'\n        n = (depth - 4) // 6\n        block = BasicBlock\n        # 1st conv before any network block\n        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        # 1st block\n        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n        # 2nd block\n        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n        # 3rd block\n        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n        # global average pooling and classifier\n        self.bn1 = nn.BatchNorm2d(nChannels[3])\n        self.relu = nn.ReLU(inplace=True)\n        self.fc = nn.Linear(nChannels[3]*64, num_classes)\n        self.nChannels = nChannels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.block1(out)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.relu(self.bn1(out))\n        out = F.avg_pool2d(out, 8)\n        #out = out.view(-1, self.nChannels)\n        out = out.view(out.size(0), -1)\n        return self.fc(out)\n\ndef wrn(**kwargs):\n    '''\n    Constructs a Wide Residual Networks.\n    '''\n    model = WideResNet(**kwargs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-10T04:29:58.133179Z","iopub.execute_input":"2023-12-10T04:29:58.133649Z","iopub.status.idle":"2023-12-10T04:29:58.157240Z","shell.execute_reply.started":"2023-12-10T04:29:58.133610Z","shell.execute_reply":"2023-12-10T04:29:58.156386Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n\nWrn = wrn(depth=28, num_classes=45).cuda()\n# 使用 DataParallel 將模型複製到多個 GPU\nWrn = nn.DataParallel(Wrn)\n\noptimizer = torch.optim.Adam(Wrn.parameters(), lr=LR)\nloss_function = nn.CrossEntropyLoss()\nlocal_train_data = copy.deepcopy(train_loader)\n\nfor epoch in range(EPOCH):\n    Wrn.train()\n    for step, (x, y) in enumerate(local_train_data):\n    # b_x = Variable(x, requires_grad=False)\n    # b_y = Variable(y, requires_grad=False)\n        b_x = x.to(device)  # 將輸入數據移動到GPU上\n        b_y = y.to(device)  # 將標籤移動到GPU上\n        out = Wrn(b_x)\n        loss = loss_function(out, b_y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if step % 100 == 0:\n            print('Epoch: {} | Step: {} | Loss: {}'.format(epoch + 1, step, loss))\n\n            \n# 容器來儲存每一輪的輸出\ntrain_predict = torch.Tensor().to(device)\ntrain_label = torch.Tensor().to(device)\ntest_predict = torch.Tensor().to(device)\ntest_label = torch.Tensor().to(device)\n\n# 在評估模式下，模型只需要在主 GPU 上執行\nWrn = Wrn.module\n\nlocal_train_loader = copy.deepcopy(train_loader)\nlocal_test_loader = copy.deepcopy(test_loader)\n# 測試集\nWrn.eval()  # 切換到評估模式\nmodel_path = '/kaggle/working/'\ntorch.save(Wrn.state_dict(), model_path+'Wrn.pth')\n\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_train_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Wrn(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        train_predict = torch.cat((train_predict, out), dim=0)\n        train_label = torch.cat((train_label, b_y), dim=0)\n\nwith torch.no_grad():  # 在評估模式下，不計算梯度\n    for step, (x, y) in enumerate(local_test_loader):\n        b_x = x.to(device)\n        b_y = y.to(device)\n        out = Wrn(b_x)\n        # 將該批次的預測結果和標籤添加到對應的容器中\n        test_predict = torch.cat((test_predict, out), dim=0)\n        test_label = torch.cat((test_label, b_y), dim=0)\n\n# train_predict、train_label 分別包含了每一輪的模型訓練集預測和標籤\n# test_predict、test_label 分別包含了模型對測試集的預測和標籤\nprint(\"Shape of train_predict:\", train_predict.shape)\nprint(\"Shape of train_label:\", train_label.shape)\nprint(\"Shape of test_predict:\", test_predict.shape)\nprint(\"Shape of test_label:\", test_label.shape)\n\n\noutput_path = OUTPUT_PATH+'train'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':train_predict,'labelVectors':train_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Wrn_28_train_prediction.pt'))\n\n\noutput_path = OUTPUT_PATH+'test'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':test_predict,'labelVectors':test_label}\ntorch.save(temp_dict, os.path.join(output_path, 'Wrn_28_test_prediction.pt'))\n            \n\n'''\n            \ntemp_train_loader = copy.deepcopy(train_loader)\ntemp_train_x, temp_train_y = next(iter(temp_train_loader))\n\nWrn.eval()  # 將模型設置為評估模式\nwith torch.no_grad():  # 關閉梯度計算\n    temp_train_x, temp_train_y = temp_train_x.to(device), temp_train_y.to(device)  # 將測試數據移動到GPU上\n    train_prediction = torch.argmax(Wrn(temp_train_x), 1)\n    acc = torch.eq(train_prediction, temp_train_y)\n    accuracy = torch.sum(acc) / acc.shape[0]\n    print('Accuracy: {:.2%}'.format(accuracy.item()))\n\n# 保存模型的方式建議使用 torch.save(model.state_dict(), path) 以保存模型的狀態字典\noutput_path = OUTPUT_PATH+'train'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':train_prediction.tolist(),'labelVectors':temp_train_y.tolist()}\ntorch.save(temp_dict, os.path.join(output_path, 'Wrn_28_train_prediction.pt'))\n\nlocal_test_loader = copy.deepcopy(test_loader)\ntemp_test_x, temp_test_y = next(iter(local_test_loader))\n\n#alexNet.eval()  # 將模型設置為評估模式\nwith torch.no_grad():  # 關閉梯度計算\n    temp_test_x, temp_test_y = temp_test_x.to(device), temp_test_y.to(device)  # 將測試數據移動到GPU上\n    prediction = torch.argmax(Wrn(temp_test_x), 1)\n    acc = torch.eq(prediction, temp_test_y)\n    accuracy = torch.sum(acc) / acc.shape[0]\n    print('Accuracy: {:.2%}'.format(accuracy.item()))\n\n# 保存模型的方式建議使用 torch.save(model.state_dict(), path) 以保存模型的狀態字典\noutput_path = OUTPUT_PATH+'test'\nif not os.path.exists(output_path):\n    os.mkdir(output_path)\ntemp_dict = {'predictionVectors':prediction.tolist(),'labelVectors':temp_test_y.tolist()}\ntorch.save(temp_dict, os.path.join(output_path, 'Wrn_28_test_prediction.pt'))\n'''","metadata":{"execution":{"iopub.status.busy":"2023-12-10T04:31:17.236104Z","iopub.execute_input":"2023-12-10T04:31:17.236458Z","iopub.status.idle":"2023-12-10T05:10:32.200019Z","shell.execute_reply.started":"2023-12-10T04:31:17.236430Z","shell.execute_reply":"2023-12-10T05:10:32.198976Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch: 1 | Step: 0 | Loss: 3.8339362144470215\nEpoch: 1 | Step: 100 | Loss: 3.527473211288452\nEpoch: 1 | Step: 200 | Loss: 3.6259005069732666\nEpoch: 1 | Step: 300 | Loss: 3.5357964038848877\nEpoch: 2 | Step: 0 | Loss: 3.137824296951294\nEpoch: 2 | Step: 100 | Loss: 3.1813905239105225\nEpoch: 2 | Step: 200 | Loss: 3.226167678833008\nEpoch: 2 | Step: 300 | Loss: 3.027867317199707\nEpoch: 3 | Step: 0 | Loss: 3.1532201766967773\nEpoch: 3 | Step: 100 | Loss: 3.101816415786743\nEpoch: 3 | Step: 200 | Loss: 3.036646842956543\nEpoch: 3 | Step: 300 | Loss: 3.03568696975708\nEpoch: 4 | Step: 0 | Loss: 2.922797918319702\nEpoch: 4 | Step: 100 | Loss: 2.4767239093780518\nEpoch: 4 | Step: 200 | Loss: 3.0411837100982666\nEpoch: 4 | Step: 300 | Loss: 2.941531181335449\nEpoch: 5 | Step: 0 | Loss: 2.5725793838500977\nEpoch: 5 | Step: 100 | Loss: 2.791670322418213\nEpoch: 5 | Step: 200 | Loss: 2.9361572265625\nEpoch: 5 | Step: 300 | Loss: 2.968845844268799\nEpoch: 6 | Step: 0 | Loss: 2.65017032623291\nEpoch: 6 | Step: 100 | Loss: 2.826472520828247\nEpoch: 6 | Step: 200 | Loss: 3.037738561630249\nEpoch: 6 | Step: 300 | Loss: 2.292970657348633\nEpoch: 7 | Step: 0 | Loss: 2.5347647666931152\nEpoch: 7 | Step: 100 | Loss: 2.452357053756714\nEpoch: 7 | Step: 200 | Loss: 2.3278658390045166\nEpoch: 7 | Step: 300 | Loss: 2.378373622894287\nEpoch: 8 | Step: 0 | Loss: 2.730154514312744\nEpoch: 8 | Step: 100 | Loss: 2.542809009552002\nEpoch: 8 | Step: 200 | Loss: 2.5091938972473145\nEpoch: 8 | Step: 300 | Loss: 1.9890202283859253\nEpoch: 9 | Step: 0 | Loss: 2.4786264896392822\nEpoch: 9 | Step: 100 | Loss: 2.347482919692993\nEpoch: 9 | Step: 200 | Loss: 2.5362508296966553\nEpoch: 9 | Step: 300 | Loss: 2.1011600494384766\nEpoch: 10 | Step: 0 | Loss: 2.487996816635132\nEpoch: 10 | Step: 100 | Loss: 2.4833009243011475\nEpoch: 10 | Step: 200 | Loss: 2.0871989727020264\nEpoch: 10 | Step: 300 | Loss: 2.0082144737243652\nEpoch: 11 | Step: 0 | Loss: 1.6604554653167725\nEpoch: 11 | Step: 100 | Loss: 2.1187126636505127\nEpoch: 11 | Step: 200 | Loss: 2.470257043838501\nEpoch: 11 | Step: 300 | Loss: 1.7493683099746704\nEpoch: 12 | Step: 0 | Loss: 2.357381582260132\nEpoch: 12 | Step: 100 | Loss: 2.361222505569458\nEpoch: 12 | Step: 200 | Loss: 2.1505439281463623\nEpoch: 12 | Step: 300 | Loss: 2.613704204559326\nEpoch: 13 | Step: 0 | Loss: 2.1292498111724854\nEpoch: 13 | Step: 100 | Loss: 2.1922707557678223\nEpoch: 13 | Step: 200 | Loss: 1.8316465616226196\nEpoch: 13 | Step: 300 | Loss: 2.466726303100586\nEpoch: 14 | Step: 0 | Loss: 2.470797300338745\nEpoch: 14 | Step: 100 | Loss: 1.8334381580352783\nEpoch: 14 | Step: 200 | Loss: 2.477794885635376\nEpoch: 14 | Step: 300 | Loss: 2.2090227603912354\nEpoch: 15 | Step: 0 | Loss: 2.2807388305664062\nEpoch: 15 | Step: 100 | Loss: 1.9239602088928223\nEpoch: 15 | Step: 200 | Loss: 2.326774835586548\nEpoch: 15 | Step: 300 | Loss: 1.9732449054718018\nEpoch: 16 | Step: 0 | Loss: 1.8518089056015015\nEpoch: 16 | Step: 100 | Loss: 1.6047990322113037\nEpoch: 16 | Step: 200 | Loss: 2.50932240486145\nEpoch: 16 | Step: 300 | Loss: 1.417116641998291\nEpoch: 17 | Step: 0 | Loss: 2.0392308235168457\nEpoch: 17 | Step: 100 | Loss: 2.2407121658325195\nEpoch: 17 | Step: 200 | Loss: 2.4680957794189453\nEpoch: 17 | Step: 300 | Loss: 2.507735252380371\nEpoch: 18 | Step: 0 | Loss: 2.144050121307373\nEpoch: 18 | Step: 100 | Loss: 1.8126654624938965\nEpoch: 18 | Step: 200 | Loss: 2.222548007965088\nEpoch: 18 | Step: 300 | Loss: 1.624457836151123\nEpoch: 19 | Step: 0 | Loss: 1.8509900569915771\nEpoch: 19 | Step: 100 | Loss: 2.4092557430267334\nEpoch: 19 | Step: 200 | Loss: 1.8244680166244507\nEpoch: 19 | Step: 300 | Loss: 2.0340616703033447\nEpoch: 20 | Step: 0 | Loss: 1.4177440404891968\nEpoch: 20 | Step: 100 | Loss: 2.245765447616577\nEpoch: 20 | Step: 200 | Loss: 1.59065580368042\nEpoch: 20 | Step: 300 | Loss: 1.5345890522003174\nEpoch: 21 | Step: 0 | Loss: 1.9362130165100098\nEpoch: 21 | Step: 100 | Loss: 1.3531752824783325\nEpoch: 21 | Step: 200 | Loss: 2.35075306892395\nEpoch: 21 | Step: 300 | Loss: 1.7077151536941528\nEpoch: 22 | Step: 0 | Loss: 1.6107759475708008\nEpoch: 22 | Step: 100 | Loss: 1.5269551277160645\nEpoch: 22 | Step: 200 | Loss: 1.6284230947494507\nEpoch: 22 | Step: 300 | Loss: 1.4468461275100708\nEpoch: 23 | Step: 0 | Loss: 1.3879202604293823\nEpoch: 23 | Step: 100 | Loss: 1.6974737644195557\nEpoch: 23 | Step: 200 | Loss: 1.4282931089401245\nEpoch: 23 | Step: 300 | Loss: 1.9074184894561768\nEpoch: 24 | Step: 0 | Loss: 1.5003025531768799\nEpoch: 24 | Step: 100 | Loss: 1.9244027137756348\nEpoch: 24 | Step: 200 | Loss: 1.7010706663131714\nEpoch: 24 | Step: 300 | Loss: 1.331174612045288\nEpoch: 25 | Step: 0 | Loss: 1.9070874452590942\nEpoch: 25 | Step: 100 | Loss: 2.2038872241973877\nEpoch: 25 | Step: 200 | Loss: 1.6712318658828735\nEpoch: 25 | Step: 300 | Loss: 2.0608229637145996\nEpoch: 26 | Step: 0 | Loss: 1.6843137741088867\nEpoch: 26 | Step: 100 | Loss: 1.5944104194641113\nEpoch: 26 | Step: 200 | Loss: 1.5090880393981934\nEpoch: 26 | Step: 300 | Loss: 1.5766029357910156\nEpoch: 27 | Step: 0 | Loss: 2.076479196548462\nEpoch: 27 | Step: 100 | Loss: 1.3439186811447144\nEpoch: 27 | Step: 200 | Loss: 2.2621355056762695\nEpoch: 27 | Step: 300 | Loss: 1.8267298936843872\nEpoch: 28 | Step: 0 | Loss: 1.7903181314468384\nEpoch: 28 | Step: 100 | Loss: 1.7120866775512695\nEpoch: 28 | Step: 200 | Loss: 1.3358750343322754\nEpoch: 28 | Step: 300 | Loss: 1.3009144067764282\nEpoch: 29 | Step: 0 | Loss: 1.0868080854415894\nEpoch: 29 | Step: 100 | Loss: 1.4520454406738281\nEpoch: 29 | Step: 200 | Loss: 1.2497673034667969\nEpoch: 29 | Step: 300 | Loss: 1.6911375522613525\nEpoch: 30 | Step: 0 | Loss: 1.294546127319336\nEpoch: 30 | Step: 100 | Loss: 1.8840200901031494\nEpoch: 30 | Step: 200 | Loss: 1.2383064031600952\nEpoch: 30 | Step: 300 | Loss: 1.35040283203125\nShape of train_predict: torch.Size([9625, 45])\nShape of train_label: torch.Size([9625])\nShape of test_predict: torch.Size([2682, 45])\nShape of test_label: torch.Size([2682])\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"\"\\n            \\ntemp_train_loader = copy.deepcopy(train_loader)\\ntemp_train_x, temp_train_y = next(iter(temp_train_loader))\\n\\nWrn.eval()  # 將模型設置為評估模式\\nwith torch.no_grad():  # 關閉梯度計算\\n    temp_train_x, temp_train_y = temp_train_x.to(device), temp_train_y.to(device)  # 將測試數據移動到GPU上\\n    train_prediction = torch.argmax(Wrn(temp_train_x), 1)\\n    acc = torch.eq(train_prediction, temp_train_y)\\n    accuracy = torch.sum(acc) / acc.shape[0]\\n    print('Accuracy: {:.2%}'.format(accuracy.item()))\\n\\n# 保存模型的方式建議使用 torch.save(model.state_dict(), path) 以保存模型的狀態字典\\noutput_path = OUTPUT_PATH+'train'\\nif not os.path.exists(output_path):\\n    os.mkdir(output_path)\\ntemp_dict = {'predictionVectors':train_prediction.tolist(),'labelVectors':temp_train_y.tolist()}\\ntorch.save(temp_dict, os.path.join(output_path, 'Wrn_28_train_prediction.pt'))\\n\\nlocal_test_loader = copy.deepcopy(test_loader)\\ntemp_test_x, temp_test_y = next(iter(local_test_loader))\\n\\n#alexNet.eval()  # 將模型設置為評估模式\\nwith torch.no_grad():  # 關閉梯度計算\\n    temp_test_x, temp_test_y = temp_test_x.to(device), temp_test_y.to(device)  # 將測試數據移動到GPU上\\n    prediction = torch.argmax(Wrn(temp_test_x), 1)\\n    acc = torch.eq(prediction, temp_test_y)\\n    accuracy = torch.sum(acc) / acc.shape[0]\\n    print('Accuracy: {:.2%}'.format(accuracy.item()))\\n\\n# 保存模型的方式建議使用 torch.save(model.state_dict(), path) 以保存模型的狀態字典\\noutput_path = OUTPUT_PATH+'test'\\nif not os.path.exists(output_path):\\n    os.mkdir(output_path)\\ntemp_dict = {'predictionVectors':prediction.tolist(),'labelVectors':temp_test_y.tolist()}\\ntorch.save(temp_dict, os.path.join(output_path, 'Wrn_28_test_prediction.pt'))\\n\""},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"#VGG\n","metadata":{"id":"uDYGBrD6HWdh"}},{"cell_type":"markdown","source":"#wrn","metadata":{"id":"7Z_G1dF9eR-q"}},{"cell_type":"markdown","source":"#else\n","metadata":{"id":"AQmEkH_cqTyS"}}]}